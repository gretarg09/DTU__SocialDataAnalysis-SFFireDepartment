<!DOCTYPE html>

<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>San Francisco fire department</title>
        <script type="text/javascript" src="d3/d3.js"></script>
        <script type="text/javascript" src="d3/d3-tip/index.js"></script>
        <link rel="stylesheet" href="style/myStyle.css">
        <link rel="stylesheet" href="style/normalize.css">
        <link rel="stylesheet" href="style/skeleton.css">
    </head>
    <body>
        <h1 >Fire Department Calls for Service</h1>
        <div class='container'>
            <div class='row'>
                <div class='twelve columns exercise-view'>
                    <h4 >Analyses of the response time of the San Francisco fire department</h4>

                    <div class="visual-container"> 
                        <div class='visual-buttons'> 
                            <a href="index.html"> <button id="page1_btn" class="visual-button banner-btns">Introduction</button></a>
                            <a href="responsetime.html"> <button id="page2_btn" class="visual-button banner-btns">Response time</button></a>
                            <a href="geoplot.html"><button id="page3_btn" class="visual-button banner-btns">Geo plot</button></a>
                            <a href="machinelearning.html"><button id="page4_btn" class="visual-button page_button_chosen banner-btns">Prediction</button></a>
                        </div>
                    <div id="Visualization1_text">
                </div>
            </div>

            <div class='row'>
                <div class='twelve columns exercise-view'>

                    <h2>Machine learning</h2>
                    <p>Our machine learning goals are two-fold. First we want to see if we can extract enough information out of the SFFD - Calls for Service data-set to predict the response time in each neighborhood each hour in the day. Secondly we want to see if we can predict if the workload within the hour in 24 hours will be below average.</p>

                    <p>For the first task we will compare KNN and RandomForest models. The training period for both models is not long as for models such as ANN and both can be used for linear non-linear and classification problems. Our feature set is limited but we have a lot of data. KNN is one of the simplest models but can be very powerful, especially when the samples far outnumber the features such as in our case. We also chose Random Forest because we are uncertain about our feature set and many of the features we might try are related, such as neighborhood, station and battalion. and one of the benefits of random forest is that itÂ´s practically impossible to overfit. It randomly samples both the samples and the feature set for a some prechosen number of trees. Then all the trees are asked and depending on the problem, a majory vote or the average of their results is used. A big reason we chose these two model was also the fact that running a dual layered cross-validation to select the best parameters for some set of models would take very long with all the data we had and we wanted instead to train models on as much data as possible, instead of the same data in different combinations and as we've mentioned the Random Forest model has sampling already in place and with so many samples we should be able to train a relatively good KNN model.</p>
                    <p>In the second task we will only be asking, will the dispatches within a given hour of the day be more or less than on average. Then we will train a logistic regression model first and use that as a baseline to compare KNN and Random Forest.
                    A thorough walkthrough of our Machine Learning Work can be found in the <a href="https://github.com/gretarg09/Dtu-SocialDataAnalysis-SFFireDepartment/blob/master/Notebook/Machine%20Learning%20Explorations.ipynb">Machine Learning Explorations notebook.</a></p>
                    <p>To train the models we split the 2016 data 80/20 into training and testing to begin with. In the first task we trained first regression models and then classification models, in the second we just trained classification models. For the regression models we used the mean squared error as a benchmark and we compared the result to guessing the mean of the training data. For the classification we used the classification rate or the % of correct classifications and the confusion matrix to measure the model preformance. In the second task we also used the precision and recall scores.</p>
                    <p>The results for our first task are somewhat expected. There are a lot of variables that could affect the response time. We've seen from the data that the response time varies a lot for many of the given variables we've explored but that does not mean that the reasons for abnomalies in the time to arrival correlate with or are captured by the variables in the dataset.
                    We had no expectations for the second task. The results are alright, Logistic Regression manages a precision score of 0.772 and recall score of 0.892. It beats the most common by 9.5% and performs better than KNN and Random Forest.</p>
                    <p>These models were just to explore the potential predictive possibilities of the data-set. We did not find a very good model for the response time, even if it's slightly better it does not warrant the effort. But we have made an indicator that can indicate to some degree if the workload in the hour 24 hours in the future is going to be below average or not.
                    </p>
                    <div class="visual-container"> 

                        <div id="area3"></div> 

                    </div>
                </div>
            </div>
        </div> 
    </body>
</html>