{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets start by getting the data\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "# Dataset url:\n",
    "# https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3\n",
    "\n",
    "data = []\n",
    "\n",
    "hour_seconds = 3600\n",
    "stationDispatches = {}\n",
    "station24HrDispatches = {}\n",
    "station48to24HrDispatches = {}\n",
    "\n",
    "def second_difference(end,start):\n",
    "    #'09/05/2014 03:33:20 AM' ->    %p\n",
    "    start_sec = datetime.strptime(start, '%m/%d/%Y %I:%M:%S %p')\n",
    "    if len(end) > 0:\n",
    "        end_sec = datetime.strptime(end, '%m/%d/%Y %I:%M:%S %p')\n",
    "        difference =(end_sec-start_sec).total_seconds()\n",
    "        if start_sec.year != 2016 or start_sec.month != 4 or start_sec.day != 25:\n",
    "            if end_sec.year != 2016 or end_sec.month != 4 or end_sec.day != 25:\n",
    "#                 if difference >= 0.0 and difference < 10800:\n",
    "                if difference >= 0.0:\n",
    "                    return int(difference)\n",
    "    return None\n",
    "    \n",
    "with open(\"../../Fire_Department_Calls_for_Service_2012-2016.csv\", \"rb\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile,delimiter=\",\")\n",
    "    for row in sorted(reader, key=lambda x:datetime.strptime(x[\"Dispatch DtTm\"], '%m/%d/%Y %I:%M:%S %p')):\n",
    "        CallDateSplit = row[\"Call Date\"].split('/')\n",
    "        CallDate = CallDateSplit[2]+'-'+CallDateSplit[0]+\"-\"+CallDateSplit[1]\n",
    "        if CallDateSplit[2] == '2017':\n",
    "            continue\n",
    "        initiateToEntry = second_difference(row['Entry DtTm'],row['Received DtTm'])\n",
    "        entryToDispatch = second_difference(row['Dispatch DtTm'],row['Entry DtTm'])\n",
    "        dispatchToArrival = second_difference(row['On Scene DtTm'],row['Dispatch DtTm'])\n",
    "        if initiateToEntry is None or entryToDispatch is None or dispatchToArrival is None:\n",
    "            continue\n",
    "        ReceivedDtTm = datetime.strptime(row[\"Received DtTm\"], '%m/%d/%Y %I:%M:%S %p') # Date and time of call is received at the 911 Dispatch Center.\n",
    "        DispatchDtTm = datetime.strptime(row[\"Dispatch DtTm\"], '%m/%d/%Y %I:%M:%S %p') # Date and time of call is received at the 911 Dispatch Center.\n",
    "        OnSceneDtTm = datetime.strptime(row[\"On Scene DtTm\"], '%m/%d/%Y %I:%M:%S %p') # Date and time the unit records arriving to the location of the incident\n",
    "        CallFinalDisposition = row[\"Call Final Disposition\"]\n",
    "        if row[\"Station Area\"] == '' or row[\"Station Area\"] == 'F3':\n",
    "            continue\n",
    "        StationArea = int(row[\"Station Area\"])\n",
    "        if StationArea not in stationDispatches:\n",
    "                stationDispatches[StationArea] = []\n",
    "        if StationArea not in station24HrDispatches:\n",
    "                station24HrDispatches[StationArea] = []\n",
    "        if StationArea not in station48to24HrDispatches:\n",
    "                station48to24HrDispatches[StationArea] = []\n",
    "        stationDispatches[StationArea].append(DispatchDtTm)\n",
    "        while (DispatchDtTm - stationDispatches[StationArea][0]).total_seconds() > hour_seconds:\n",
    "            stationDispatches[StationArea].pop(0)\n",
    "        station24HrDispatches[StationArea].append(DispatchDtTm)\n",
    "        while (DispatchDtTm - station24HrDispatches[StationArea][0]).total_seconds() > hour_seconds*24:\n",
    "            station24HrDispatches[StationArea].pop(0)\n",
    "        station48to24HrDispatches[StationArea].append(DispatchDtTm)\n",
    "        while (DispatchDtTm - station48to24HrDispatches[StationArea][0]).total_seconds() > hour_seconds*48:\n",
    "            station48to24HrDispatches[StationArea].pop(0)\n",
    "        Box = -1\n",
    "        if row['Box'] is not None and len(row['Box']) > 0 and 'AI' not in row['Box']:\n",
    "            Box = int(row['Box'])\n",
    "        data.append({\n",
    "            \"CallNumber\":row[\"Call Number\"],\n",
    "            \"CallType\":row[\"Call Type\"],\n",
    "            \"CallDate\":CallDate,\n",
    "            \"ReceivedDtTm\":ReceivedDtTm,\n",
    "            \"DispatchDtTm\":DispatchDtTm,\n",
    "            \"OnSceneDtTm\":OnSceneDtTm,\n",
    "            \"InitiateToEntry\":initiateToEntry,\n",
    "            \"EntryToDispatch\":entryToDispatch,\n",
    "            \"DispatchToArrival\":dispatchToArrival,\n",
    "            \"Box\":Box,\n",
    "            \"CallFinalDisposition\":CallFinalDisposition,\n",
    "            \"StationArea\":StationArea,\n",
    "            \"FinalPriority\":int(row[\"Final Priority\"]),\n",
    "            \"CallTypeGroup\":row[\"Call Type Group\"], #Call types are divided into four main groups: Fire, Alarm, Potential Life Threatening and Non Life Threatening., \n",
    "            \"UnitType\":row[\"Unit Type\"],\n",
    "            \"UnitId\":row[\"Unit ID\"],\n",
    "            \"Battalion\":int(row['Battalion'][1:]),\n",
    "            \"NeighborhoodDistrict\":row[\"Neighborhood  District\"],\n",
    "            \"Location\":row[\"Location\"],\n",
    "            \"StationDispatches\":len(stationDispatches[StationArea]),\n",
    "            \"Station24HrDispatches\":len(station24HrDispatches[StationArea]),\n",
    "            \"Station48to24HrDispatches\":len([x for x in station48to24HrDispatches[StationArea] if \n",
    "                 (DispatchDtTm - station48to24HrDispatches[StationArea][0]).total_seconds() >= hour_seconds*24])\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/fire_station_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a98b22848ab0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcytoolz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurried\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtlz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfirestations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/fire_station_data.json'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mfirestations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtlz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/fire_station_data.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cytoolz.curried as tlz\n",
    "firestations = {}\n",
    "with open('fire_station_data.json') as f:    \n",
    "    firestations = tlz.groupby(lambda x:x['station'],json.loads(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Wayne Dyck\n",
    "import math\n",
    "def haversine(origin, destination):\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "    return d\n",
    "\n",
    "def getlatlonpair(location):\n",
    "    return [float(location.strip(\"()\").split(\",\")[0]), \n",
    "            float(location.strip(\"()\").split(\",\")[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiple units can be called out for each call therefore multiple lines can be created for each call.\n",
    "# We decided to group the data by call number and extract the relevant data.\n",
    "import cytoolz.curried as tlz\n",
    "import io\n",
    "from operator import itemgetter\n",
    "data_grouped = tlz.groupby(lambda x: x['CallNumber'],data)\n",
    "for d in data_grouped:\n",
    "    temp = {\n",
    "        'CallType': \"\",\n",
    "        'CallTypeGroup': \"\",\n",
    "        'ReceivedHour': -1,\n",
    "        'ReceivedYear': -1,\n",
    "        'frTimeToArrival': float(\"inf\"),\n",
    "        'frUnitId': -1,\n",
    "        'frUnitType': -1,\n",
    "        'NeighborhoodDistrict': \"\",\n",
    "        'Battalion':-1,\n",
    "        'Lat': None,\n",
    "        'Lon': None,\n",
    "        'Weekend':False,\n",
    "        'FinalPriority': -1,\n",
    "        'CallFinalDisposition': \"\",\n",
    "        'StationArea': -1,\n",
    "        'DirectDistance': -1,\n",
    "        'NbrhoodDispatches': -1,\n",
    "        'BattalionDispatches': -1,\n",
    "        'StationDispatches': -1,\n",
    "        'Station24HrDispatches': -1,\n",
    "        'Station48to24HrDispatches': -1,\n",
    "        'Box':-1\n",
    "    }\n",
    "    for line in data_grouped[d]:\n",
    "        timeToArrival = line['InitiateToEntry']+line['EntryToDispatch']+line['DispatchToArrival']\n",
    "        if temp['frTimeToArrival'] > timeToArrival:\n",
    "            temp['frTimeToArrival'] = timeToArrival\n",
    "            temp['frUnitType'] = line['UnitType']\n",
    "            temp['frUnitId'] = line['UnitId']\n",
    "            temp['StationDispatches'] = line['StationDispatches']\n",
    "            temp['Battalion'] = line['Battalion']\n",
    "            temp['NeighborhoodDistrict'] = line['NeighborhoodDistrict']\n",
    "            temp['Lat'],temp['Lon'] = getlatlonpair(line['Location']) \n",
    "            temp['FinalPriority'] = line['FinalPriority']\n",
    "            temp['CallFinalDisposition'] = line['CallFinalDisposition']\n",
    "            temp['CallDate'] = line['CallDate']\n",
    "            temp['StationArea'] = line['StationArea']\n",
    "            if line['StationArea'] in [47,94]:\n",
    "                continue\n",
    "            temp['DirectDistance'] = haversine((temp['Lat'],temp['Lon']),\n",
    "                                               (firestations[str(temp['StationArea'])][0]['latitude'],\n",
    "                                               firestations[str(temp['StationArea'])][0]['longitude']))\n",
    "            temp['CallType'] = line['CallType']\n",
    "            temp['CallTypeGroup'] = line['CallTypeGroup']\n",
    "            temp['ReceivedHour'] = line['ReceivedDtTm'].hour\n",
    "            temp['ReceivedYear'] = line['ReceivedDtTm'].year\n",
    "            temp['Box'] = line['Box']\n",
    "            temp['Station24HrDispatches'] = line['Station24HrDispatches']\n",
    "            temp['Station48to24HrDispatches'] = line['Station48to24HrDispatches']\n",
    "    data_grouped[d] = temp\n",
    "data_grouped = sorted(data_grouped.values(), key=itemgetter('CallDate','NeighborhoodDistrict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Exporting grouped data\n",
    "with open('general_data.json','w+') as f:\n",
    "    f.write(json.dumps(data_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cytoolz.curried as tlz\n",
    "count = 0\n",
    "for stuff in tlz.filter(lambda x:x['StationArea'] == 1,data_grouped):\n",
    "    print stuff['StationArea'], stuff['CallDate'],stuff['StationDispatches'],stuff['NbrhoodDispatches'],stuff['BattalionDispatches']\n",
    "    count = count+ 1\n",
    "    if count == 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Exporting late first response\n",
    "import numpy as np\n",
    "filter_final = tlz.filter(lambda x:x['FinalPriority'] != 4)\n",
    "filter_nonlife = tlz.filter(lambda x:x['CallTypeGroup'] != 'Non Life-threatening')\n",
    "stuff = filter_final(filter_nonlife(data_grouped))\n",
    "nbrhood_group = tlz.groupby(lambda x:x['NeighborhoodDistrict'])\n",
    "filter_dec2016 = tlz.filter(lambda x:x['CallDate'].split('-')[0]+x['CallDate'].split('-')[1] == '201612')\n",
    "filter_late = tlz.filter(lambda x:x['frTimeToArrival'] > 600)\n",
    "hood_map_data = []\n",
    "for hood,vals in nbrhood_group(stuff).iteritems():\n",
    "    if hood == 'None':\n",
    "        continue\n",
    "    hood_map_data.append({\n",
    "        'hood':hood,\n",
    "        'avg-response':np.mean([x['frTimeToArrival'] for x in vals]),\n",
    "        'avg-distance':np.mean([x['DirectDistance'] for x in vals]),\n",
    "        'late-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>600])/\n",
    "                np.sum([x['frTimeToArrival'] for x in vals]),\n",
    "        'verylate-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>1200])/\n",
    "                np.sum([x['frTimeToArrival'] for x in vals])\n",
    "        })\n",
    "\n",
    "with io.open(\"hood_map_data.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(hood_map_data)))\n",
    "\n",
    "latenessess = []\n",
    "# for row in tlz.filter(lambda x:x['ReceivedYear'] == 2016,data_grouped):\n",
    "for row in filter_dec2016(filter_late(data_grouped)):\n",
    "    response = row['frTimeToArrival']\n",
    "    lateness = 0\n",
    "    if response < 600:\n",
    "        continue\n",
    "    elif response > 1200:\n",
    "        lateness = 1\n",
    "    latenessess.append({\n",
    "        'lat':round(row['Lat'],5),\n",
    "        'lon':round(row['Lon'],5),\n",
    "        'howLate':lateness,\n",
    "        'distance':row['DirectDistance'],\n",
    "        'station':row['StationArea']\n",
    "        })\n",
    "with io.open(\"late_arrivals_dec2016.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(latenessess)))\n",
    "latenessess = []\n",
    "# for row in tlz.filter(lambda x:x['ReceivedYear'] == 2016,data_grouped):\n",
    "for row in sorted(filter_late(data_grouped),key=itemgetter('frTimeToArrival'),reverse=True)[:200]:\n",
    "    response = row['frTimeToArrival']\n",
    "    lateness = 0\n",
    "    if response < 600:\n",
    "        continue\n",
    "    elif response > 1200:\n",
    "        lateness = 1\n",
    "    latenessess.append({\n",
    "        'lat':round(row['Lat'],5),\n",
    "        'lon':round(row['Lon'],5),\n",
    "        'howLate':lateness,\n",
    "        'distance':row['DirectDistance'],\n",
    "        'station':row['StationArea']\n",
    "        })\n",
    "with io.open(\"late_arrivals_200worst.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(latenessess))) \n",
    "#Performance rating suggestions\n",
    "maxavg = max([x['avg-response'] for x in hood_map_data])\n",
    "minavg = min([x['avg-response'] for x in hood_map_data])\n",
    "median = np.median([x['avg-response'] for x in hood_map_data])\n",
    "print minavg, minavg+(median-minavg)/2,median, median+(maxavg-median)/2,maxavg\n",
    "print int((minavg+(median-minavg)/2)/60)*60+60,int((median)/60)*60+60,int((median+(maxavg-median)/2)/60)*60+60\n",
    "maxavg = max([x['avg-distance'] for x in hood_map_data])\n",
    "minavg = min([x['avg-distance'] for x in hood_map_data])\n",
    "median = np.median([x['avg-distance'] for x in hood_map_data])\n",
    "print minavg, minavg+(median-minavg)/2,median, median+(maxavg-median)/2,maxavg\n",
    "maxavg = max([x['late-ratio'] for x in hood_map_data])\n",
    "minavg = min([x['late-ratio'] for x in hood_map_data])\n",
    "median = np.median([x['late-ratio'] for x in hood_map_data])\n",
    "print minavg, minavg+(median-minavg)/2,median, median+(maxavg-median)/2,maxavg\n",
    "maxavg = max([x['verylate-ratio'] for x in hood_map_data])\n",
    "minavg = min([x['verylate-ratio'] for x in hood_map_data])\n",
    "median = np.median([x['verylate-ratio'] for x in hood_map_data])\n",
    "print minavg, minavg+(median-minavg)/2,median, median+(maxavg-median)/2,maxavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export late Gone on Arrivals\n",
    "late_goa = []\n",
    "filter_gone = tlz.filter(lambda x:x['CallFinalDisposition'] == 'Gone on Arrival')\n",
    "for row in filter_late(filter_gone(data_grouped)):\n",
    "    late_goa.append({\n",
    "        'lat':round(row['Lat'],5),\n",
    "        'lon':round(row['Lon'],5),\n",
    "        'response':row['frTimeToArrival'],\n",
    "        'distance':row['DirectDistance'],\n",
    "        'station':row['StationArea']\n",
    "        })\n",
    "with io.open(\"late_arrivals_GOA.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(late_goa))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export response times\n",
    "from __future__ import division\n",
    "ctg_grouping = tlz.groupby(lambda x:x['CallTypeGroup'])\n",
    "year_grouping = tlz.groupby(lambda x:x['ReceivedYear'])\n",
    "nbrhood_group = tlz.groupby(lambda x:x['NeighborhoodDistrict'])\n",
    "hour_group = tlz.groupby(lambda x:x['ReceivedHour'])\n",
    "\n",
    "def hoodgregations(data):\n",
    "    ret = []\n",
    "    for hood,vals in sorted(nbrhood_group(data).iteritems(),key=lambda x:x[0]):\n",
    "        if hood == 'None':\n",
    "            continue\n",
    "        ret.append({\n",
    "            'hood':hood,\n",
    "            'response':{'avg':np.mean([x['frTimeToArrival'] for x in vals]),\n",
    "                        'hourly':[np.mean([x['frTimeToArrival'] for x in v]) for k,v in sorted(hour_group(vals).iteritems(),key=lambda x:x[0])]},\n",
    "            'distance':{'avg':np.mean([x['DirectDistance'] for x in vals])},\n",
    "            'late-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>600])/\n",
    "                    np.sum([x['frTimeToArrival'] for x in vals]),\n",
    "            'verylate-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>1200])/\n",
    "                    np.sum([x['frTimeToArrival'] for x in vals])})\n",
    "    return ret\n",
    "response_time_groups = {}\n",
    "response_time_groups['combinedoverall'] = hoodgregations(data_grouped)\n",
    "for year, valsj in sorted(year_grouping(data_grouped).iteritems(),key=lambda x:x[0]):\n",
    "        response_time_groups['combined'+str(year)] = hoodgregations(valsj)\n",
    "for ctg, vals in sorted(ctg_grouping(data_grouped).iteritems(),key=lambda x:x[0]):\n",
    "    if ctg == '':\n",
    "        continue\n",
    "    response_time_groups[ctg.replace(' ','')+'overall'] = hoodgregations(vals)\n",
    "    for year, valsj in sorted(year_grouping(vals).iteritems(),key=lambda x:x[0]):\n",
    "        response_time_groups[ctg.replace(' ','')+str(year)] = hoodgregations(valsj)\n",
    "with io.open(\"response_time_groups.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(response_time_groups))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_time_groups.keys()# Export response times\n",
    "from __future__ import division\n",
    "nlt_filter = tlz.filter(lambda x:x['CallTypeGroup'] in ['Alarm','Fire','Potentially Life-Threatening'])\n",
    "ctg_grouping = tlz.groupby(lambda x:x['CallTypeGroup'])\n",
    "year_grouping = tlz.groupby(lambda x:x['ReceivedYear'])\n",
    "nbrhood_group = tlz.groupby(lambda x:x['NeighborhoodDistrict'])\n",
    "hour_group = tlz.groupby(lambda x:x['ReceivedHour'])\n",
    "\n",
    "def getTheGoods(hood,vals):\n",
    "    return {'hood':hood,\n",
    "    'response':{'avg':np.mean([x['frTimeToArrival'] for x in vals]),\n",
    "                'hourly':[np.mean([x['frTimeToArrival'] for x in v]) for k,v in sorted(hour_group(vals).iteritems(),key=lambda x:x[0])]},\n",
    "    'distance':{'avg':np.mean([x['DirectDistance'] for x in vals])},\n",
    "    'late-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>600])/\n",
    "            np.sum([x['frTimeToArrival'] for x in vals]),\n",
    "    'verylate-ratio':np.sum([x['frTimeToArrival'] for x in vals if x['frTimeToArrival']>1200])/\n",
    "            np.sum([x['frTimeToArrival'] for x in vals])}\n",
    "    ''\n",
    "\n",
    "def hoodgregations(data):\n",
    "    ret = []\n",
    "    for hood,vals in sorted(nbrhood_group(data).iteritems(),key=lambda x:x[0]):\n",
    "        if hood == 'None':\n",
    "            continue\n",
    "        ret.append(getTheGoods(hood,vals))\n",
    "    return ret\n",
    "\n",
    "response_time_groups = {}\n",
    "response_time_groups['combinedoverall'] = hoodgregations(nlt_filter(data_grouped))\n",
    "response_time_groups['sanfranoverall'] = getTheGoods('San Fransisco',list(nlt_filter(data_grouped)))\n",
    "for year, valsj in sorted(year_grouping(nlt_filter(data_grouped)).iteritems(),key=lambda x:x[0]):\n",
    "        response_time_groups['combined'+str(year)] = hoodgregations(valsj)\n",
    "        response_time_groups['sanfran'+str(year)] =getTheGoods('San Fransisco',valsj)\n",
    "for ctg, vals in sorted(ctg_grouping(nlt_filter(data_grouped)).iteritems(),key=lambda x:x[0]):\n",
    "    if ctg == '':\n",
    "        continue\n",
    "    response_time_groups[ctg.replace(' ','')+'overall'] = hoodgregations(vals)\n",
    "    for year, valsj in sorted(year_grouping(vals).iteritems(),key=lambda x:x[0]):\n",
    "        response_time_groups[ctg.replace(' ','')+str(year)] = hoodgregations(valsj)\n",
    "with io.open(\"response_time_groups_nltfree.json\",\"w+\",encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(response_time_groups))) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
